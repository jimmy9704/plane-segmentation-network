{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpvL68OfBEQC",
    "tags": []
   },
   "source": [
    "## HKPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6137,
     "status": "ok",
     "timestamp": 1626412726399,
     "user": {
      "displayName": "‍이홍재[학생](전자정보대학 전자공학과)",
      "photoUrl": "",
      "userId": "15375391309743651264"
     },
     "user_tz": -540
    },
    "id": "TJ47VNF7fmTS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "sys.path.append('./utils')\n",
    "import Hybrid_kmeans\n",
    "import Pointnet\n",
    "import Merge\n",
    "import Visualize\n",
    "import Normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mLBRcfwP2Sq",
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1626412727412,
     "user": {
      "displayName": "‍이홍재[학생](전자정보대학 전자공학과)",
      "photoUrl": "",
      "userId": "15375391309743651264"
     },
     "user_tz": -540
    },
    "id": "nvmmwhcePvt2",
    "outputId": "e518d821-2713-453e-95ac-7c78f35521c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "(67, 1600, 3)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "pointnet = Pointnet.PointNet()\n",
    "pointnet.to(device);\n",
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)\n",
    "\n",
    "# load dataset\n",
    "# The dataset is an unorganized point cloud in the form of Nx3 (xyz)\n",
    "# preprocessed by voxel downsamling.\n",
    "dataset = np.load(\"./dataset/with_noise.npy\",allow_pickle=True)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1626412880806,
     "user": {
      "displayName": "‍이홍재[학생](전자정보대학 전자공학과)",
      "photoUrl": "",
      "userId": "15375391309743651264"
     },
     "user_tz": -540
    },
    "id": "UUwps4dnix4q"
   },
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    return criterion(outputs, labels)\n",
    "\n",
    "def make_labels(dataset,max_k=15,iteration=10):\n",
    "    labels = np.zeros(len(dataset))\n",
    "    for size in range(len(dataset)):\n",
    "      print(\"make labels %d / %d: \" % (int(size)+1,len(dataset)))\n",
    "      loss = np.zeros(max_k)\n",
    "      for k in range(1,max_k+1):\n",
    "        k = int(k)\n",
    "        #Kmeans\n",
    "        #labels_,outputs,cos_loss,centroids = Hybrid_kmeans.Kmeans(dataset[size],k,10)\n",
    "        #Hybrid_Kmeans\n",
    "        labels_,outputs,cos_loss,centroids = Hybrid_kmeans.Kmeans_normal(dataset[size],k,iter=iteration)\n",
    "        loss[k-1] = cos_loss \n",
    "      labels[size] = max_k-1\n",
    "      for i in range(max_k-1,0,-1):\n",
    "        if ((loss[i-1]-loss[i]) > 0.01):\n",
    "          labels[size] = i\n",
    "          break\n",
    "      print(\"label : \",labels[size]+1)\n",
    "      np.save(\"HKPS_labels\",labels)\n",
    "    \n",
    "def train(model,dataset_,train_loss, epochs=5,make_label=True, save=True):\n",
    "    \n",
    "    #you can change 'max_k' and 'iteration'\n",
    "    #'max_k' is the maximum number that PointNet will estimate\n",
    "    #'iteration' is the number of Hybrid-Kmeans iterations\n",
    "    #'iteration' can be reduced to reduce time consumption\n",
    "    #but it might cause unstable results\n",
    "    if (make_label == True):\n",
    "        make_labels(dataset,max_k=15,iteration=10)\n",
    "    \n",
    "    #normalize dataset\n",
    "    dataset = Normalize.normalize(dataset_)\n",
    "    \n",
    "    labels_ = np.load(\"HKPS_labels.npy\",allow_pickle=True)\n",
    "\n",
    "    print(\"Labels: \",labels_ +1 )\n",
    "    print(\"train pointnet\")\n",
    "    inputs_, labels_ = torch.tensor(dataset).to(device).float(), torch.tensor(labels_).to(device).long()\n",
    "    for epoch in range(epochs): \n",
    "        shuf_idx = np.random.permutation(len(labels_))\n",
    "        inputs_ = inputs_[shuf_idx]\n",
    "        labels_ = labels_[shuf_idx]\n",
    "\n",
    "        pointnet.train()\n",
    "        batch_size = int(len(inputs_)/20)\n",
    "        for i in range(batch_size):\n",
    "            inputs = inputs_[20*i:20*(i+1)]\n",
    "            labels = labels_[20*i:20*(i+1)]\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "            outputs_ = F.softmax(outputs)\n",
    "            outputs_ = torch.argmax(outputs_,dim =1)\n",
    "\n",
    "            loss = pointnetloss(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # print statistics\n",
    "            print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, batch_size, loss.item()), end='\\r')\n",
    "\n",
    "        pointnet.eval()\n",
    "        inputs_val = inputs_[:20]\n",
    "        labels_val = labels_[:20]      \n",
    "        outputs, m3x3, m64x64 = pointnet(inputs_val.transpose(1,2))\n",
    "        outputs_ = F.softmax(outputs)\n",
    "        outputs_ = torch.argmax(outputs_,dim =1)\n",
    "\n",
    "        loss = pointnetloss(outputs, labels_val)\n",
    "        print(\"                                                   \", end='\\r')\n",
    "        print(\"Epoch: %d, valid loss : %.3f\" %(epoch + 1, loss.item()), end='\\r')\n",
    "\n",
    "        # save the model\n",
    "        if save:\n",
    "          torch.save(pointnet.state_dict(), \"./model_save/save_\"+str(epoch)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22693056,
     "status": "ok",
     "timestamp": 1626435577530,
     "user": {
      "displayName": "‍이홍재[학생](전자정보대학 전자공학과)",
      "photoUrl": "",
      "userId": "15375391309743651264"
     },
     "user_tz": -540
    },
    "id": "Lp3uFKomP8AU",
    "outputId": "48d9b18d-031c-4cfb-afbb-3638b415b8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.479565740705611, -90.89614486694336, -3.7586827278137207]\n",
      "[149.84942626953125, 91.87315368652344, 22.7500057220459]\n",
      "x_range : 0.0 1.0\n",
      "y_range : 0.0 1.0\n",
      "z_range : 0.0 1.0\n",
      "Labels:  [10. 14. 14. 11. 15. 12. 11. 14. 13. 14. 14. 15. 15. 14.  8. 15. 14. 15.\n",
      " 15. 10.  5. 14. 14. 14.  7.  6.  6.  5.  5. 13.  5.  4.  9.  4.  5.  4.\n",
      "  4.  4.  4.  4.  3.  4.  4.  4. 14. 15. 15. 15. 15. 15. 15. 15.  4. 15.\n",
      " 15. 15. 15.  9.  8. 10.  2. 15.  2.  2.  2.  2.  2.]\n",
      "train pointnet\n",
      "Epoch: 50, valid loss : 0.915                      \r"
     ]
    }
   ],
   "source": [
    "#if you want to make labels for PointNet training run make_labels or modify make_label as True\n",
    "#'iteration' can be reduced to reduce time consumption\n",
    "#but it might cause unstable results\n",
    "\n",
    "train_loss = []\n",
    "#make_labels(dataset,max_k=15,iteration=10)\n",
    "train(pointnet, dataset,train_loss, epochs=50,make_label=False, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdFwxOz7FkO0",
    "tags": []
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, dataset,save_num=99,iteration=10):\n",
    "  if(len(dataset.shape) <3):\n",
    "    dataset = dataset.reshape(1,1600,-1)\n",
    "  #normalize dataset\n",
    "  dataset_normal = Normalize.normalize(dataset)\n",
    "\n",
    "  inputs = torch.tensor(dataset_normal).to(device).float()\n",
    "  file = \"./model_save/save_\" + str(save_num) + \".pth\"\n",
    "  pointnet.load_state_dict(torch.load(file))\n",
    "  print(inputs.shape)\n",
    "  pointnet.eval()\n",
    "  with torch.no_grad():\n",
    "    outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "  outputs_ = F.softmax(outputs)\n",
    "  outputs_ = torch.argmax(outputs_,dim =1)\n",
    "\n",
    "  print(\"PointNet result: \", outputs_ + 1)\n",
    "  K = np.asarray(outputs_.cpu()+1)\n",
    "  for n in range(len(K)):\n",
    "      print(\"%d / %d\" %(n+1, len(K)))\n",
    "      labels_k_,outputs_k,cos_loss,centroids = Hybrid_kmeans.Kmeans_normal(dataset[n],K[n],iter=iteration)\n",
    "      labels_k = Merge.PlaneMerge(outputs_k,np.copy(labels_k_),K[n])\n",
    "      result_file = \"HKPS_\" + str(n)\n",
    "      Visualize.visualize(labels_k,outputs_k,result_file)\n",
    "  print(\"Result Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results are saved as result_HKPS_'index'.txt\n",
    "#The result is shape as xyzRGB\n",
    "#'iteration' can be reduced to reduce time consumption\n",
    "#but it might cause unstable results\n",
    "valid(pointnet, dataset[:10], save_num=99,iteration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu101\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Train_KNPE.ipynb",
   "provenance": [
    {
     "file_id": "1K6Js7gCDvdZQGZeMS1OCVcJJbCMk0WG1",
     "timestamp": 1618387032564
    },
    {
     "file_id": "1BB0ZAqdHe1KdD52n3Sd0qlHjAxeWHRoZ",
     "timestamp": 1617340996803
    },
    {
     "file_id": "https://github.com/nikitakaraevv/pointnet/blob/master/nbs/PointNetClass.ipynb",
     "timestamp": 1617209242715
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
